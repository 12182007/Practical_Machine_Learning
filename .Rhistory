# Total all emissions for the years 1999 to 2008
totalNEI <- tapply(NEI$Emissions, NEI$year, sum)
# Plot output to file
# png("plot1.png", width = 480, height = 480)
png(filename='C:/Users/yli/Documents/assignment_Exploratory Data Analysis/plot1.png',width=480,height=480)
par(bg = 'grey')
barplot(totalNEI, col = rainbow(10, start = 0, end = 1),
xlab = "Year", ylab = "Total PM2.5 Emissions in Tons", main = "Total PM 2.5 Emissions (tons) in USA")
dev.off()
getwd()
setwd(C:/Users/yli/Documents/assignment_Exploratory Data Analysis/)
setwd(/Users/yli/Documents/assignment_Exploratory Data Analysis/)
pwd
cd
ls
getwd()
library()
library(swirl)
swirl()
dim(pm0)
head(pm0)
cnames
q()
libaray()
libaray(swirl)
libarary(swirl)
library(swirl)
swirl()
strsplit(cnames,"|",fixed=TRUE)
cnames<-strsplit(cnames,"|",fixed=TRUE)
cnames
q()
q()
library(swirl)
swirl()
install_from_swirl("Statistical Inference")
swirl()
q()
set seed(2016)
set.seed(2016)
n<-40
lamda<-0.2
sim<-1000
plot(rexp(20000,lamda),pch=20,cex=50,main="The exponential distribution with")
plot(rexp(10000,lamda),pch=20,cex=0.5,main="The exponential distribution with rate 0.2 and 10000 observations")
means<-NULL
for(i in 1:sim)means<-c(means,mean(rexp(n,lamda)))
hist(means,col="green",main="rexp meand distribution breaks=40")
rug(means)
hist(means,col="green",main="rexp meand distribution breaks=15")
rug(means)
hist(means,col="green",main="rexp meand distribution breaks=60")
rug(means)
hist(means,col="green",main="rexp meand distribution breaks=10")
rug(means)
hist(means,col="green",main="rexp meand distribution breaks=40")
rug(means)
hist(means,col="green",main="rexp meand distribution breaks=20")
rug(means)
hist(means,col="green",main="Theoretical vs actual mean for rexp()",reaks=30)
hist(means,col="green",main="Theoretical vs actual mean for rexp()",breaks=30)
abline(v=mean(means),lwd="3",col="red")
text(3.6,80,paste("Actual mean= ",round(mean(means),2),"\n Theoretical mean=5"),col="black")
text(2.0,80,paste("Actual mean= ",round(mean(means),2),"\n Theoretical mean=5"),col="black")
text(3.6,80,paste("Actual mean= ",round(mean(means),2),"\n Theoretical mean=5"),col="black")
print (paste("Theoretical standard deviation: ", round( (1/lambda)/sqrt(n) ,4), ", Practical standard deviation", round(sd(means) ,4) ) )
print (paste("Theoretical standard deviation:",round((1/lamda)/sqrt(n),4),",Practical standard deviation",round(sd(means),4)))
print(paste("Theoretical variance:",(1/lamda)^2/n,",Practical variance",round(var(means),4)))
hist(means,prob=TRUE, col="lightblue",main="mean distribution for rexp()",breaks=20)
lines(density(means),lwd=3,col="blue")
hist(means,prob=TRUE, col="black",main="mean distribution for rexp()",breaks=20)
hist(means,prob=TRUE, col="lightred",main="mean distribution for rexp()",breaks=20)
hist(means,prob=TRUE, col="gray",main="mean distribution for rexp()",breaks=20)
lines(density(means),lwd=3,col="red")
library(datasets)
data(ToothGrowth)
head(ToothGrowth)
str(ToothGrowth)
suppplot<-ggplot(aes(x = supp, y = len), data = ToothGrowth) + geom_boxplot(aes(fill = supp))
q()
---
print (c("ssss"))
total.steps <- tapply(activity$steps, activity$date, FUN=sum, na.rm=T)
mean.interval
x <- "MiXeD cAsE 123"
chartr("iXs", "why",x)
tolower(x)
```{r}
}
storm <- read.csv(bzfile("data/repdata-data-StormData.csv.bz2"))
echo = TRUE
length(unique(storm$EVTYPE))
The most severe weather event in terms of crop damage is the drought. In the last half century, the drought has caused more than 10 billion dollars damage. Other severe crop-damage-causing event types are floods and hails.
# update the data frame
Before the analysis, the data need some preprocessing. Event types don't have a specific format. For instance, there are events with types Frost/Freeze, FROST/FREEZE and FROST\\FREEZE which obviously refer to the same type of event.
storm <- read.csv("C:/Users/yli/Documents/Case-Studies-Commentaries-assignment2/repdata_data_StormData.csv.bz2")
library(ggplot2)
library(gridExtra)
library(ggplot2)
head(storm)
rawData <- read.csv("C:/Users/yli/Documents/Case-Studies-Commentaries-assignment2/repdata_data_StormData.csv.bz2")
length(unique(rawData$EVTYPE))
head(unique(rawData$EVTYPE))
rawData$EVTYPE)
rawData$EVTYPE
head(unique(rawData$EVTYPE))
length(unique(rawData$EVTYPE))
event_types <- tolower(rawData$EVTYPE)
event_types
p1 <- ggplot(data=cropDmg[1:10],
aes(x=reorder(EVTYPE, fatalities), y=fatalities, fill=fatalities)) +
geom_bar(stat="identity") +
coord_flip() +
ylab("Total number of fatalities") +
xlab("Event type") +
theme(legend.position="none")
library(ggplot2)
#library(gridExtra)
# Set the levels in order
p1 <- ggplot(data=cropDmg[1:10],
aes(x=reorder(EVTYPE, fatalities), y=fatalities, fill=fatalities)) +
geom_bar(stat="identity") +
coord_flip() +
ylab("Total number of fatalities") +
xlab("Event type") +
theme(legend.position="none")
#adjust property damage
myData$myPropDmg <- myData$PROPDMG
myData$myPropDmg[myData$PROPDMGEXP == "K"] <-
myData$PROPDMG[myData$PROPDMGEXP == "K"] * 1000
myData$myPropDmg[myData$PROPDMGEXP == "M"] <-
myData$PROPDMG[myData$PROPDMGEXP == "M"] * 1000000
myData$myPropDmg[myData$PROPDMGEXP == "B"] <-
myData$PROPDMG[myData$PROPDMGEXP == "B"] * 1000000
#adjust crop damage
myData$myCropDmg <- myData$CROPDMG
myData$myCropDmg[myData$CROPDMGEXP == "K"] <-
myData$CROPDMG[myData$CROPDMGEXP == "K"] * 1000
myData$myCropDmg[myData$CROPDMGEXP == "M"] <-
myData$CROPDMG[myData$CROPDMGEXP == "M"] * 1000000
myData$myCropDmg[myData$CROPDMGEXP == "B"] <-
myData$CROPDMG[myData$CROPDMGEXP == "B"] * 1000000
#turn everything back into M's
myData$myPropDmg <- myData$myPropDmg / 1000000000
myData$myCropDmg <- myData$myCropDmg / 1000000000
#concentrate on propDmg events
propDmg <- tapply(myData$myPropDmg, myData$myEVTYPE, FUN=sum, na.rm=TRUE)
propDmg <- propDmg[order(propDmg, decreasing=TRUE)]
#concentrate on propDmg events
cropDmg <- tapply(myData$myCropDmg, myData$myEVTYPE, FUN=sum, na.rm=TRUE)
cropDmg <- cropDmg[order(cropDmg, decreasing=TRUE)]
#combine crop and prop damage
allDmg <- c(cropDmg, propDmg)
allDmg <- allDmg[order(allDmg, decreasing=TRUE)]
```
Here we begin to correlate fatality producing events
```{r}
#get only fatalities
fatalities <- tapply(myData$FATALITIES, myData$myEVTYPE, FUN=sum, na.rm=TRUE)
#gets all Fatalities
allFatalities <- fatalities[order(fatalities, decreasing=TRUE)]
#takes only top ten fatality producing events
topFatalities <- allFatalities[1:10]
topFatalities
```
Next, I will show you the top ten injury producing events
```{r}
#to get only the Injuries
Injuries <- tapply(myData$INJURIES, myData$myEVTYPE, FUN=sum, na.rm=TRUE)
#to get all the Injuries
allInjuries <- Injuries[order(Injuries, decreasing=TRUE)]
#to take only top ten casuality producing events
topInjuries <- allInjuries[1:10]
topInjuries
```
All Injuries and Fatalities are most harmful with respect to population health
```{r}
#Combine/add Injuries and Fatalities
#topHealth <- topFatalities + topInjuries
topHealth <- c(topInjuries, topFatalities)
topHealth
```
# Results
## Question 1
Across the United States, which types of events (as indicated in the EVTYPE variable) are most harmful with respect to population health?
Answer:
Apparently,  that “tornado” and “high wind” events were the most hazardous to overall population health.
```{r}
barplot(topHealth[1:5]/1000,
main="Events causing fatalities and injuries",
col=c("black"),
xlab="Event",
ylab="Frequency in thousands",
ylim=c(0,100))
```
## Question 2
Across the United States, which types of events have the greatest economic consequences?
Answer:
The highest property damage event was “tornado” with damage of $51.7B
The highest crop damage event was “flood” with damage of $7.25B
The top damange producing, economic event was “tornado” with damage at $51.7B
Here we look at the Crop Damage Events
```{r}
barplot(allDmg[1:5],
xlab="Event",
ylab="Damage (Billions)",
main="Top 5 Economic Damaging Events",
col=c("yellow"),
ylim=c(0,60))
```
Final Conclusion
If we compare everything side by side, we can see some insights.
```{r}
library(lattice)
library(ggplot2)
#couple variables to make life easier when plotting
my_las <- 2
par(mfrow=c(2,2))
par(mar=c(9,3,1,1))
barplot(cropDmg[1:10],
ylab="Damage (Billions)",
main="Top Crop Damage Events",
col=c("blue"),
las=my_las,
ylim=c(0,60))
barplot(propDmg[1:10],
ylab="Damage (Billions)",
main="Top Property Damaging Events",
col=c("black"),
las=my_las,
ylim=c(0,60))
barplot(allInjuries[1:10]/1000,
col=c("yellow"),
ylab="Frequency (thousands)",
main="Top Injury Events",
las=my_las,
ylim=c(0,100))
barplot(allFatalities[1:10]/1000,
col=c("purple"),
ylab="Frequency (thousands)",
main="Top Fatality Events",
las=my_las,
ylim=c(0,100))
```
file.edit('~/.Rprofile')
install_from_swirl("Regression Models")
install_from_swirl("Regression Models")
swirl
swirl()
q()
x<-mtcars$wt
summary(mtcars)
help(mtcars)
swirl()
install_from_swirl("Regression Models")
library(swirl)
swirl()
lm(child~parent)
fit<-lm(child~parent)
fit<-lm(child ~ parent)
fit<-lm(child ~ parent)
fit<-lm.(child ~ parent)
fit<-lm(child ~ parent)
fit<-lm(child ~ parent,data='galton')
fit<-lm(child ~ parent,galton)
summary(fit)
mean(fit$residuals)
library(swirl)
swirl()
cov(fit$residuals,galton$parent)
fit<-lm(mpg ~ weight, data=mtcars)
fit<-lm(child ~ parent,galton)
fit<-lm(mpg ~ weight, data=mtcars)
fit<-lm(mpg ~ cylinders, data=mtcars)
summary(mtcars)
summary(mtcars)
fit<-lm(mpg ~ cyl, data=mtcars)
summary(mtcars)
lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
library(swirl)
install_from_swirl("Regression Models")
swirl()
swirl()
swirl()
plot(child~parent,galton)
plot(jitter(child,4)~parent,galton)
regrline<-lm(chile~parent,galton)
regrline<-lm(child~parent,galton)
abline(regrline,lwd=3,col='red')
q()
swirl()
myPlot <- function(beta){
y <- galton$child - mean(galton$child)
x <- galton$parent - mean(galton$parent)
freqData <- as.data.frame(table(x, y))
names(freqData) <- c("child", "parent", "freq")
plot(
as.numeric(as.vector(freqData$parent)),
as.numeric(as.vector(freqData$child)),
pch = 21, col = "black", bg = "lightblue",
cex = .15 * freqData$freq,
xlab = "parent",
ylab = "child"
)
abline(0, beta, lwd = 3)
points(0, 0, cex = 2, pch = 19)
mse <- mean( (y - beta * x)^2 )
title(paste("beta = ", beta, "mse = ", round(mse, 3)))
}
#manipulate(myPlot(beta), beta = slider(0.4, .8, step = 0.02))
myPlot <- function(beta){
y <- galton$child - mean(galton$child)
x <- galton$parent - mean(galton$parent)
freqData <- as.data.frame(table(x, y))
names(freqData) <- c("child", "parent", "freq")
plot(
as.numeric(as.vector(freqData$parent)),
as.numeric(as.vector(freqData$child)),
pch = 21, col = "black", bg = "lightblue",
cex = .15 * freqData$freq,
xlab = "parent",
ylab = "child"
)
abline(0, beta, lwd = 3)
points(0, 0, cex = 2, pch = 19)
mse <- mean( (y - beta * x)^2 )
title(paste("beta = ", beta, "mse = ", round(mse, 3)))
}
manipulate(myPlot(beta), beta = slider(0.4, .8, step = 0.02))
library(manipulate)
myPlot <- function(beta){
y <- galton$child - mean(galton$child)
x <- galton$parent - mean(galton$parent)
freqData <- as.data.frame(table(x, y))
names(freqData) <- c("child", "parent", "freq")
plot(
as.numeric(as.vector(freqData$parent)),
as.numeric(as.vector(freqData$child)),
pch = 21, col = "black", bg = "lightblue",
cex = .15 * freqData$freq,
xlab = "parent",
ylab = "child"
)
abline(0, beta, lwd = 3)
points(0, 0, cex = 2, pch = 19)
mse <- mean( (y - beta * x)^2 )
title(paste("beta = ", beta, "mse = ", round(mse, 3)))
}
manipulate(myPlot(beta), beta = slider(0.4, .8, step = 0.02))
myPlot <- function(beta){
y <- galton$child - mean(galton$child)
x <- galton$parent - mean(galton$parent)
freqData <- as.data.frame(table(x, y))
names(freqData) <- c("child", "parent", "freq")
plot(
as.numeric(as.vector(freqData$parent)),
as.numeric(as.vector(freqData$child)),
pch = 21, col = "black", bg = "lightblue",
cex = .15 * freqData$freq,
xlab = "parent",
ylab = "child"
)
abline(0, beta, lwd = 6)
points(0, 0, cex = 2, pch = 19)
mse <- mean( (y - beta * x)^2 )
title(paste("beta = ", beta, "mse = ", round(mse, 3)))
}
manipulate(myPlot(beta), beta = slider(0.4, .8, step = 0.02))
data(mtcars)
head(mtcars)
summary(mtcars)
data(mtcars)
summary(mtcars)
head -20 mtcars
head(mtcars)
library(corrplot)
install.packages( pkgs= "coorplot" )
library(MASS)
?shuttle
head(shuttle)
shuttle$use.binary <- as.integer(shuttle$use == "auto")
fit <- glm(use.binary ~ wind - 1 , data = shuttle, family = binomial)
summary(fit)$coef
fit <- glm(use.binary ~ wind - 2 , data = shuttle, family = binomial)
fit <- glm(use.binary ~ wind - 0.5 , data = shuttle, family = binomial)
fit <- glm(use.binary ~ wind - 1 , data = shuttle, family = binomial)
summary(fit)$coef
data(mtcars)
fit <- lm(100/mpg ~ disp + hp + wt + am, data = mtcars)
confint(fit)
summary(fit)
data(InsectSprays)
head(InsectSprays)
InsectSprays$spray<-as.factor(InsectSprays1$spray)
fit<-glm(count~InsectSprays$spray-1, data=InsectSprays)
InsectSprays$spray<-as.factor(InsectSprays$spray)
fit<-glm(count~InsectSprays$spray-1, data=InsectSprays)
summary(fit)
fit<-glm(count~factor(spray)-1, data=InsectSprays)
summary(fit)
fit<-glm(count~factor(spray)-1, family="poisson", data=InsectSprays)
summary(fit)
library(AppliedpredictiveModeling)
library(AppliedPredictiveModeling)
library(AppliedPredictiveModeling)
AppliedPredictiveModeling
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(Hmisc)
data(AlzheimerDisease)
summary(AlzheimerDisease)
test<-data(AlzheimerDisease)
summary(test)
adData = data.frame(diagnosis, predictors)
head(adData)
summary(adData)
adData = data.frame(diagnosis, predictors)
colnames(adData)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain=createDataPartition(mixtures$CompressiveStrength,p=3/4)[[1]]
training=mixtures[inTrain,]
testing=mixtures[-intrain,]
testing=mixtures[-inTrain,]
names<-colnames(concrete)
names<-names[-length(names)]
names
names<-names[length(names)]
names
names<-names[-length(names)]
names<-colnames(concrete)
names
names<-names[-length(names)]
names
data(concrete)
library(caret)
set.seed(1000)
inTrain=createDataPartition(mixtures$CompressiveStrength,p=3/4)[[1]]
summary(mixtures)
summary(mixtures)
training = mixtures[inTrain, ]
testing = mixtures[-inTrain, ]
set.seed(3433)
data(AlzheimerDisease)
data(AlzheimerDisease)
adData=data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
inTrain=createDataPartition(adData$diagnosis,p=3/4)[[1]]
training=adData[inTrain,]
testing=adData[-inTrain]
testing=adData[-inTrain,]
IL_str<-grep("^IL",colnames(training),value=True)
IL_str<-grep("^IL",colnames(training),value=TRUE)
preProc<-preProcess(training[,IL_str],method="pca",thresh=0.8)
preProc$rotation
summary(preProc)
summary(preProc)
preProc$rotation
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain<-createDataPartition(y=Wage$wage,p=0.7,list=FALSE)
library(rpart)
library(ggplot2)
library(rattle)
load(rattle)
install.packages("Rattle")
install.packages("rattle")
library(rattle)
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Test",]
set.seed(125)
model<-train(Class ~ .,)
model<-train(Class ~ .,data=training, method="rpart")
install.packages('e1071')
model<-train(Class ~ .,data=training, method="rpart")
fancyRpartPlot(model$finalModel)
install.packages(rpart.plot)
set.seed(125)
model<-train(Class ~ .,data=training, method="rpart")
fancyRpartPlot(model$finalModel)
inTrain<-createDataPartition(y=segmentationOriginal$Case, p=0.6, list= FALSE)
inTrain<-createDataPartition(y=segementationOriginal$case,p=0.6,list=FALSE)
inTrain<-createDataPartition(y=segmentationOriginal$Case, p=0.6, list= FALSE)
training<-segmentationOriginal[inTrain,]
testing<-segmentationOriginal[-inTrain,]
set.seed(125)
modFit<-train(Class ~ ., method="rpart",data=training)
modFit$finalModel
suppressMessages(library(rattle))
library(rpart.plot)
install.packages(rpart.plot)
install.packages(rpart.plot)
fancyRpartPlot(modFit$finalModel)
library(pgmm)
install.packages(pgmm)
install.package(pgmm)
install.packages(pgmm)
download.file(url = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", destfile = "pml-testing.csv")
download.file(url = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", destfile = "pml-testing.csv")
setwd("C:\Users\yli\Documents\Practical_Machine_Learning")
setwd("C:/Users/yli/Documents/Practical_Machine_Learning")
download.file(url = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", destfile = "pml-testing.csv")
dim(testingdata)
library(lattice)
library(kernlab)
install.packages("kernlab")
library(randomForest)
install.packages("randomForest")
